{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac63f464",
      "metadata": {
        "id": "ac63f464"
      },
      "outputs": [],
      "source": [
        "from enum import Enum, auto\n",
        "import random\n",
        "from collections import deque\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Deque, Dict, List, Optional, Set, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Percept Definition"
      ],
      "metadata": {
        "id": "_Wby9wfNHauH"
      },
      "id": "_Wby9wfNHauH"
    },
    {
      "cell_type": "code",
      "source": [
        "class Percept:\n",
        "    # Attributes:\n",
        "          # time_step (int): Current time step in the episode.\n",
        "          # bump (bool): True if the agent bumped into a wall on this step.\n",
        "          # breeze (bool): True if the agent is adjacent to a pit.\n",
        "          # stench (bool): True if the agent is adjacent to a live Wumpus.\n",
        "          # scream (bool): True if the agent hears a scream (Wumpus killed).\n",
        "          # glitter (bool): True if there is gold in the agent's current square.\n",
        "          # reward (int): Reward obtained for the last action.\n",
        "          # done (bool): True if the episode has terminated.\n",
        "\n",
        "    # Type annotations\n",
        "    time_step: int\n",
        "    bump: bool\n",
        "    breeze: bool\n",
        "    stench: bool\n",
        "    scream: bool\n",
        "    glitter: bool\n",
        "    reward: int\n",
        "    done: bool\n",
        "\n",
        "    def __init__(self, time_step: int, bump: bool, breeze: bool, stench: bool,\n",
        "                 scream: bool, glitter: bool, reward: int, done: bool):\n",
        "        \"\"\"Initialize all percept attributes.\"\"\"\n",
        "        self.time_step = time_step\n",
        "        self.bump = bump\n",
        "        self.breeze = breeze\n",
        "        self.stench = stench\n",
        "        self.scream = scream\n",
        "        self.glitter = glitter\n",
        "        self.reward = reward\n",
        "        self.done = done\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"Return a readable string summarizing this percept.\"\"\"\n",
        "        active_signals = []\n",
        "        if self.bump:\n",
        "            active_signals.append(\"Bump\")\n",
        "        if self.breeze:\n",
        "            active_signals.append(\"Breeze\")\n",
        "        if self.stench:\n",
        "            active_signals.append(\"Stench\")\n",
        "        if self.scream:\n",
        "            active_signals.append(\"Scream\")\n",
        "        if self.glitter:\n",
        "            active_signals.append(\"Glitter\")\n",
        "\n",
        "        signals_str = \", \".join(active_signals) if active_signals else \"None\"\n",
        "        return (f\"Percept(t={self.time_step}, \"\n",
        "                f\"Signals=[{signals_str}], Reward={self.reward}, Done={self.done})\")\n"
      ],
      "metadata": {
        "id": "8ZYBSIioJ7l-"
      },
      "id": "8ZYBSIioJ7l-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify if pecept class works\n",
        "p = Percept(time_step=1, bump=False, breeze=True, stench=False,\n",
        "            scream=False, glitter=True, reward=-1, done=False)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1Opm5oIIPRw",
        "outputId": "4c54a3b3-50c9-409b-816e-3bcdd078945c"
      },
      "id": "x1Opm5oIIPRw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percept(t=1, Signals=[Breeze, Glitter], Reward=-1, Done=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Action Defintion"
      ],
      "metadata": {
        "id": "cYjc4xeqMZ8V"
      },
      "id": "cYjc4xeqMZ8V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39dc5f78",
      "metadata": {
        "id": "39dc5f78"
      },
      "outputs": [],
      "source": [
        "class Action(Enum):\n",
        "    # Turn left (rotate 90° counter-clockwise)\n",
        "    LEFT = 0\n",
        "\n",
        "    # Turn right (rotate 90° clockwise)\n",
        "    RIGHT = 1\n",
        "\n",
        "    # Move one cell forward in the current orientation\n",
        "    FORWARD = 2\n",
        "\n",
        "    # Pick up gold if present in the current square\n",
        "    GRAB = 3\n",
        "\n",
        "    # Fire the arrow (only once) in the current facing direction\n",
        "    SHOOT = 4\n",
        "\n",
        "    # Climb out of the cave (only valid from the start cell)\n",
        "    CLIMB = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Action.GRAB.name)   # 'GRAB'\n",
        "print(Action.GRAB.value)  # 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682roA-xNwIX",
        "outputId": "aede4179-c004-4ba0-9f6a-98d2865499ab"
      },
      "id": "682roA-xNwIX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRAB\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Orientation Definition"
      ],
      "metadata": {
        "id": "tNxln0xjN1YT"
      },
      "id": "tNxln0xjN1YT"
    },
    {
      "cell_type": "code",
      "source": [
        "class Orientation(Enum):\n",
        "    E = 0\n",
        "    S = 1\n",
        "    W = 2\n",
        "    N = 3\n",
        "\n",
        "    def symbol(self) -> str:\n",
        "        \"\"\"Return the single-letter code representing this orientation.\"\"\"\n",
        "        return self.name  # e.g., Orientation.E -> \"E\"\n",
        "\n",
        "    def symbol(self) -> str:\n",
        "            \"\"\"Return a visual arrow symbol representing this orientation.\"\"\"\n",
        "            symbols = {\n",
        "                Orientation.E: \"→\",\n",
        "                Orientation.S: \"↓\",\n",
        "                Orientation.W: \"←\",\n",
        "                Orientation.N: \"↑\"\n",
        "            }\n",
        "            return symbols[self]\n",
        "\n",
        "\n",
        "    def turn_right(self) -> 'Orientation':\n",
        "        \"\"\"Return a new orientation turned 90° clockwise.\"\"\"\n",
        "        # Clockwise rotation: E → S → W → N → E\n",
        "        return Orientation((self.value + 1) % 4)\n",
        "\n",
        "    def turn_left(self) -> 'Orientation':\n",
        "        \"\"\"Return a new orientation turned 90° counter-clockwise.\"\"\"\n",
        "        # Counterclockwise rotation: E → N → W → S → E\n",
        "        return Orientation((self.value - 1) % 4)"
      ],
      "metadata": {
        "id": "U8LermzmO4iD"
      },
      "id": "U8LermzmO4iD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o = Orientation.E\n",
        "print(o.symbol())          # E\n",
        "print(o.turn_right())      # Orientation.S\n",
        "print(o.turn_left())       # Orientation.N\n",
        "print(o.turn_left().name)  # N\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMu3hCdZUH1E",
        "outputId": "fd6f0f93-d678-460c-ee66-3d71c95fc293"
      },
      "id": "zMu3hCdZUH1E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→\n",
            "Orientation.S\n",
            "Orientation.N\n",
            "N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Location Definition"
      ],
      "metadata": {
        "id": "GRTf4TGoXMLW"
      },
      "id": "GRTf4TGoXMLW"
    },
    {
      "cell_type": "code",
      "source": [
        "class Location:\n",
        "    \"\"\"\n",
        "        Represents a single cell in the Wumpus World grid.\n",
        "\n",
        "        The coordinate system is 1-based:\n",
        "            - (1,1) is the bottom-left corner (the starting cell for the agent).\n",
        "            - x increases to the East (right).\n",
        "            - y increases to the North (up).\n",
        "    \"\"\"\n",
        "    x: int\n",
        "    y: int\n",
        "\n",
        "    def __init__(self, x: int, y: int):\n",
        "        \"\"\"Initialize a location with x and y coordinates.\"\"\"\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Return a human-readable string representation, e.g., '(2, 3)'.\"\"\"\n",
        "        return f'({self.x}, {self.y})'\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # RELATIVE POSITION CHECKS\n",
        "    # ---------------------------------------------------------------------\n",
        "    def is_left_of(self, location: 'Location') -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this location is immediately to the LEFT of another location.\n",
        "        That means:\n",
        "            - Both are on the same row (same y-coordinate)\n",
        "            - This cell's x-coordinate is exactly one less than the other.\n",
        "        \"\"\"\n",
        "        return self.y == location.y and self.x == location.x - 1\n",
        "\n",
        "    def is_right_of(self, location: 'Location') -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this location is immediately to the RIGHT of another location.\n",
        "        Conditions:\n",
        "            - Both share the same row\n",
        "            - This cell's x is exactly one greater.\n",
        "        \"\"\"\n",
        "        return self.y == location.y and self.x == location.x + 1\n",
        "\n",
        "    def is_above(self, location: 'Location') -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this location is immediately ABOVE another location.\n",
        "        Conditions:\n",
        "            - Both share the same column\n",
        "            - This cell’s y is exactly one greater.\n",
        "        \"\"\"\n",
        "        return self.x == location.x and self.y == location.y + 1\n",
        "\n",
        "    def is_below(self, location: 'Location') -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this location is immediately BELOW another location.\n",
        "        Conditions:\n",
        "            - Both share the same column\n",
        "            - This cell’s y is exactly one less.\n",
        "        \"\"\"\n",
        "        return self.x == location.x and self.y == location.y - 1\n",
        "\n",
        "    def neighbours(self, width: int = 4, height: int = 4) -> List['Location']:\n",
        "        \"\"\"\n",
        "        Return a list of the four adjacent (cardinal) neighbors of this cell.\n",
        "        Directions considered: East, West, North, South.\n",
        "        The function automatically removes cells that would be outside a width×height grid.\n",
        "        \"\"\"\n",
        "        # Generate all four cardinal neighbors\n",
        "        candidates = [\n",
        "            Location(self.x + 1, self.y),  # East neighbor\n",
        "            Location(self.x - 1, self.y),  # West neighbor\n",
        "            Location(self.x, self.y + 1),  # North neighbor\n",
        "            Location(self.x, self.y - 1),  # South neighbor\n",
        "        ]\n",
        "\n",
        "        # Keep only those inside the grid (1..width, 1..height)\n",
        "        return [c for c in candidates if 1 <= c.x <= width and 1 <= c.y <= height]\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # LOCATION COMPARISON\n",
        "    # ---------------------------------------------------------------------\n",
        "    def is_location(self, location: 'Location') -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this location has exactly the same coordinates as another.\n",
        "\n",
        "        This is a convenience wrapper around coordinate equality (x and y both match).\n",
        "        Example:\n",
        "            Location(2, 3).is_location(Location(2, 3)) → True\n",
        "            Location(2, 3).is_location(Location(3, 3)) → False\n",
        "        \"\"\"\n",
        "        return self.x == location.x and self.y == location.y\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # EDGE DETECTION (used for wall/boundary logic)\n",
        "    # ---------------------------------------------------------------------\n",
        "    def at_left_edge(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this cell is at the LEFT boundary of the grid.\n",
        "        Left edge means x == 1 (no valid cells further west).\n",
        "        \"\"\"\n",
        "        return self.x == 1\n",
        "\n",
        "    def at_right_edge(self, width: int = 4) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this cell is at the RIGHT boundary of the grid (x == width).\n",
        "        \"\"\"\n",
        "        return self.x == width\n",
        "\n",
        "    def at_top_edge(self, height: int = 4) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this cell is at the TOP boundary of the grid (y == height).\n",
        "        \"\"\"\n",
        "        return self.y == height\n",
        "\n",
        "    def at_bottom_edge(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if this cell is at the BOTTOM boundary of the grid.\n",
        "        The bottom edge corresponds to y == 1.\n",
        "        \"\"\"\n",
        "        return self.y == 1\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # MOVE FORWARD OPERATION\n",
        "    # ---------------------------------------------------------------------\n",
        "    def forward(self, orientation: 'Orientation',\n",
        "                width: int = 4, height: int = 4) -> bool:\n",
        "        \"\"\"\n",
        "        Attempt to move one cell forward in the given orientation on a width×height grid.\n",
        "        This method updates the agent’s current coordinates based on which\n",
        "        direction they are facing (E, W, N, S).\n",
        "\n",
        "        If the move would take the agent *outside the grid boundaries*, then:\n",
        "            • The position is left unchanged.\n",
        "            • The function returns True to indicate a \"bump\" percept.\n",
        "\n",
        "        If the move is valid and inside the grid:\n",
        "            • The coordinates are updated to the new location.\n",
        "            • The function returns False (no bump occurred).\n",
        "        \"\"\"\n",
        "        # Store tentative next position\n",
        "        nx, ny = self.x, self.y\n",
        "\n",
        "        # Determine next cell based on orientation\n",
        "        if orientation.name == \"E\":\n",
        "            nx += 1      # move right\n",
        "        elif orientation.name == \"W\":\n",
        "            nx -= 1      # move left\n",
        "        elif orientation.name == \"N\":\n",
        "            ny += 1      # move upward\n",
        "        else:  # orientation.name == \"S\"\n",
        "            ny -= 1      # move downward\n",
        "\n",
        "        # Check if new position is within 1..width and 1..height\n",
        "        if not (1 <= nx <= width and 1 <= ny <= height):\n",
        "            # Out of bounds → agent bumps into wall, position unchanged\n",
        "            return True\n",
        "\n",
        "        # Valid move → update coordinates\n",
        "        self.x, self.y = nx, ny\n",
        "        return False\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # SETTER / COPY UTILITIES\n",
        "    # ---------------------------------------------------------------------\n",
        "    def set_to(self, location: 'Location'):\n",
        "        \"\"\"\n",
        "        Set this location's coordinates to match another location (in-place).\n",
        "\n",
        "        This is a convenience method to update the current object without creating\n",
        "        a new Location instance.\n",
        "        \"\"\"\n",
        "        self.x, self.y = location.x, location.y\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # LINEAR INDEX CONVERSIONS (row-major from bottom row)\n",
        "    # ---------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def from_linear(n: int, width: int = 4, height: int = 4) -> 'Location':\n",
        "        \"\"\"\n",
        "        Convert a 0-based linear index (0..width*height-1) into 1-based grid coordinates (x, y).\n",
        "\n",
        "        Mapping uses row-major order with the bottom row first:\n",
        "            0 → (1,1), 1 → (2,1), ..., (width-1) → (width,1),\n",
        "            width → (1,2), ..., (width*height-1) → (width,height)\n",
        "        \"\"\"\n",
        "        if not (0 <= n < width * height):\n",
        "            raise ValueError(f\"Linear index out of bounds (0..{width*height-1}).\")\n",
        "\n",
        "        # Compute 1-based coordinates for a width×height grid\n",
        "        x = (n % width) + 1\n",
        "        y = (n // width) + 1\n",
        "        return Location(x, y)\n",
        "\n",
        "    def to_linear(self, width: int = 4) -> int:\n",
        "        \"\"\"\n",
        "        Convert this (x, y) location into a 0-based linear index for a width×height grid.\n",
        "\n",
        "        This is the inverse of from_linear(), using the same row-major mapping:\n",
        "            (1,1) → 0, (2,1) → 1, ..., (width,1) → (width-1),\n",
        "            (1,2) → width, ..., (width,height) → (width*height-1)\n",
        "        \"\"\"\n",
        "        # Shift both coordinates to 0-based, then compute row-major index.\n",
        "        return (self.y - 1) * width + (self.x - 1)\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # RANDOM SAMPLING ON THE GRID\n",
        "    # ---------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def random(width: int = 4, height: int = 4) -> 'Location':\n",
        "        \"\"\"\n",
        "        Sample a uniformly random cell on a width×height grid (1-based coordinates).\n",
        "        \"\"\"\n",
        "        import random as _rnd\n",
        "        return Location(_rnd.randint(1, width), _rnd.randint(1, height))\n"
      ],
      "metadata": {
        "id": "re_JDbSLpgDH"
      },
      "id": "re_JDbSLpgDH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Definition"
      ],
      "metadata": {
        "id": "bEryoNsj1BMe"
      },
      "id": "bEryoNsj1BMe"
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment:\n",
        "    wumpus_location: Location\n",
        "    wumpus_alive: bool\n",
        "    agent_location: Location\n",
        "    agent_orientation: Orientation\n",
        "    agent_has_arrow: bool\n",
        "    agent_has_gold: bool\n",
        "    game_over: bool\n",
        "    gold_location: Location\n",
        "    pit_locations: List[Location]\n",
        "    time_step: int\n",
        "    WIDTH: int\n",
        "    HEIGHT: int\n",
        "    allow_climb_without_gold: bool\n",
        "    pit_prob: float\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # EPISODE INITIALIZATION\n",
        "    # ---------------------------------------------------------------------\n",
        "    def init(self, width: int = 4, height: int = 4,\n",
        "             pit_prob: float = 0.2, allow_climb_without_gold: bool = True):\n",
        "        \"\"\"\n",
        "        Reset the world and start a new episode.\n",
        "\n",
        "        World layout (width×height, 1-based):\n",
        "          - Agent starts at (1,1), facing East, with one arrow and no gold.\n",
        "          - Place exactly one Wumpus (not at start), alive.\n",
        "          - Place exactly one Gold (not at start).\n",
        "          - For each non-start cell, place a Pit with probability `pit_prob`.\n",
        "            (Overlaps with Wumpus/Gold are allowed; start is always safe.)\n",
        "        \"\"\"\n",
        "        # Store config/state flags\n",
        "        self.WIDTH = width\n",
        "        self.HEIGHT = height\n",
        "        self.pit_prob = pit_prob\n",
        "        self.allow_climb_without_gold = allow_climb_without_gold\n",
        "\n",
        "        # Agent state\n",
        "        self.agent_location = Location(1, 1)\n",
        "        self.agent_orientation = Orientation.E\n",
        "        self.agent_has_arrow = True\n",
        "        self.agent_has_gold = False\n",
        "\n",
        "        # Episode flags\n",
        "        self.game_over = False\n",
        "        self.time_step = 0\n",
        "\n",
        "        # World objects\n",
        "        self.make_wumpus()\n",
        "        self.make_gold()\n",
        "        self.make_pits(self.pit_prob)\n",
        "\n",
        "        # Initial percept (no action taken yet → reward=0; bump/scream=False)\n",
        "        return Percept(\n",
        "            time_step=self.time_step,\n",
        "            bump=False,\n",
        "            breeze=self.is_breeze(),\n",
        "            stench=self.is_stench(),\n",
        "            scream=False,\n",
        "            glitter=self.is_glitter(),\n",
        "            reward=0,\n",
        "            done=self.game_over\n",
        "        )\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # RANDOM PLACEMENT HELPERS\n",
        "    # ---------------------------------------------------------------------\n",
        "    def make_wumpus(self):\n",
        "        \"\"\"\n",
        "        Choose a random location for the Wumpus (not the start) and set alive=True.\n",
        "        Overlap with pits/gold is allowed.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            loc = Location.random(self.WIDTH, self.HEIGHT)\n",
        "            if not loc.is_location(Location(1, 1)):\n",
        "                self.wumpus_location = loc\n",
        "                self.wumpus_alive = True\n",
        "                return\n",
        "\n",
        "    def make_gold(self):\n",
        "        \"\"\"\n",
        "        Choose a random location for the Gold (not the start).\n",
        "        Overlap with pits/Wumpus is allowed.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            loc = Location.random(self.WIDTH, self.HEIGHT)\n",
        "            if not loc.is_location(Location(1, 1)):\n",
        "                self.gold_location = loc\n",
        "                return\n",
        "\n",
        "    def make_pits(self, pit_prob: float):\n",
        "        \"\"\"\n",
        "        For every non-start cell, independently place a Pit with probability `pit_prob`.\n",
        "        \"\"\"\n",
        "        pits: List[Location] = []\n",
        "        for n in range(self.WIDTH * self.HEIGHT):\n",
        "            cell = Location.from_linear(n, self.WIDTH, self.HEIGHT)\n",
        "            if cell.is_location(Location(1, 1)):\n",
        "                continue  # start is always safe\n",
        "            if random.random() < pit_prob:\n",
        "                pits.append(cell)\n",
        "        self.pit_locations = pits\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # LOCATION QUERIES (safe, explicit comparisons w/o relying on __eq__/__hash__)\n",
        "    # ---------------------------------------------------------------------\n",
        "    def is_pit_at(self, location: Location) -> bool:\n",
        "        \"\"\"Return True if there is a Pit at `location`.\"\"\"\n",
        "        return any(p.is_location(location) for p in self.pit_locations)\n",
        "\n",
        "    def is_pit_adjacent_to_agent(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if a Pit is in any cardinally adjacent cell to the agent\n",
        "        (or same cell—though if same cell, agent is dying/just died).\n",
        "        \"\"\"\n",
        "        here = self.agent_location\n",
        "        if self.is_pit_at(here):\n",
        "            return True\n",
        "        for n in here.neighbours(self.WIDTH, self.HEIGHT):\n",
        "            if self.is_pit_at(n):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def is_wumpus_adjacent_to_agent(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if the (alive) Wumpus is in a cardinal neighbor (or same cell).\n",
        "        \"\"\"\n",
        "        if not self.wumpus_alive:\n",
        "            return False\n",
        "        here = self.agent_location\n",
        "        if self.is_wumpus_at(here):\n",
        "            return True\n",
        "        for n in here.neighbours(self.WIDTH, self.HEIGHT):\n",
        "            if self.is_wumpus_at(n):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def is_agent_at_hazard(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if the agent is on a Pit or on the (alive) Wumpus.\n",
        "        Used immediately after a successful Forward to check death.\n",
        "        \"\"\"\n",
        "        return self.is_pit_at(self.agent_location) or (\n",
        "            self.is_wumpus_at(self.agent_location) and self.wumpus_alive\n",
        "        )\n",
        "\n",
        "    def is_wumpus_at(self, location: Location) -> bool:\n",
        "        \"\"\"Return True if the Wumpus is at `location` (alive or dead).\"\"\"\n",
        "        return self.wumpus_location is not None and self.wumpus_location.is_location(location)\n",
        "\n",
        "    def is_agent_at(self, location: Location) -> bool:\n",
        "        \"\"\"Return True if the agent is at `location`.\"\"\"\n",
        "        return self.agent_location.is_location(location)\n",
        "\n",
        "    def is_gold_at(self, location: Location) -> bool:\n",
        "        \"\"\"Return True if the Gold is at `location` (i.e., not yet grabbed).\"\"\"\n",
        "        return self.gold_location is not None and self.gold_location.is_location(location)\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # PERCEPT QUERIES (Breeze / Stench / Glitter)\n",
        "    # ---------------------------------------------------------------------\n",
        "    def is_glitter(self) -> bool:\n",
        "        \"\"\"Return True if the agent is in the same cell as the Gold.\"\"\"\n",
        "        return self.is_gold_at(self.agent_location)\n",
        "\n",
        "    def is_breeze(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if a Pit is adjacent (or same cell).\n",
        "        Note: if agent is in a Pit, they will die that step; including 'same cell'\n",
        "        here makes the percept logic monotone and easy to read.\n",
        "        \"\"\"\n",
        "        return self.is_pit_adjacent_to_agent()\n",
        "\n",
        "    def is_stench(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if the (alive) Wumpus is adjacent (or same cell).\n",
        "        If the Wumpus is dead, there is no Stench.\n",
        "        \"\"\"\n",
        "        return self.is_wumpus_adjacent_to_agent()\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # FIRING LINE / COMBAT HELPERS\n",
        "    # ---------------------------------------------------------------------\n",
        "    def wumpus_in_line_of_fire(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if, from the agent’s current cell and orientation,\n",
        "        the Wumpus lies strictly ahead in the same row or column.\n",
        "        \"\"\"\n",
        "        if not (self.wumpus_alive and self.wumpus_location):\n",
        "            return False\n",
        "\n",
        "        ax, ay = self.agent_location.x, self.agent_location.y\n",
        "        wx, wy = self.wumpus_location.x, self.wumpus_location.y\n",
        "\n",
        "        if self.agent_orientation.name == \"E\":\n",
        "            return wy == ay and wx > ax\n",
        "        if self.agent_orientation.name == \"W\":\n",
        "            return wy == ay and wx < ax\n",
        "        if self.agent_orientation.name == \"N\":\n",
        "            return wx == ax and wy > ay\n",
        "        # SOUTH\n",
        "        return wx == ax and wy < ay\n",
        "\n",
        "    def kill_attempt(self) -> bool:\n",
        "        \"\"\"\n",
        "        If the Wumpus is alive and in the line of fire, kill it and return True.\n",
        "        Otherwise, return False.\n",
        "        \"\"\"\n",
        "        if self.wumpus_alive and self.wumpus_in_line_of_fire():\n",
        "            self.wumpus_alive = False\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # MAIN TRANSITION FUNCTION\n",
        "    # ---------------------------------------------------------------------\n",
        "    def step(self, action: Action) -> Percept:\n",
        "        \"\"\"\n",
        "        Apply an action, update state, and return the resulting Percept.\n",
        "\n",
        "        Reward components:\n",
        "            - Base per-step cost:             -1  (always)\n",
        "            - First SHOOT (arrow available): -10  (consumes arrow)\n",
        "            - Death (Pit or live Wumpus):  -1000  (terminal)\n",
        "            - CLIMB at (1,1) with Gold:   +1000  (terminal)\n",
        "            - CLIMB at (1,1) without Gold:\n",
        "                * if allow_climb_without_gold=True → terminal with only step cost\n",
        "                * else ignored (no termination, still pays step cost)\n",
        "        \"\"\"\n",
        "        assert not self.game_over, \"Episode already finished. Call init() for a new one.\"\n",
        "        self.time_step += 1\n",
        "\n",
        "        # Transient signals for this step\n",
        "        bump = False\n",
        "        scream = False\n",
        "\n",
        "        # Base step cost\n",
        "        reward = -1\n",
        "\n",
        "        # ---------------------------\n",
        "        # Dispatch on action\n",
        "        # ---------------------------\n",
        "        if action == Action.LEFT:\n",
        "            self.agent_orientation = self.agent_orientation.turn_left()\n",
        "\n",
        "        elif action == Action.RIGHT:\n",
        "            self.agent_orientation = self.agent_orientation.turn_right()\n",
        "\n",
        "        elif action == Action.FORWARD:\n",
        "            # Try to move forward; Location.forward returns True if bumped (no move)\n",
        "            bumped = self.agent_location.forward(self.agent_orientation, self.WIDTH, self.HEIGHT)\n",
        "            bump = bumped\n",
        "            if not bumped:\n",
        "                # After a successful move, check for fatal hazards\n",
        "                if self.is_agent_at_hazard():\n",
        "                    reward += -1000\n",
        "                    self.game_over = True\n",
        "\n",
        "        elif action == Action.GRAB:\n",
        "            # Pick up gold if present\n",
        "            if self.is_glitter():\n",
        "                self.agent_has_gold = True\n",
        "                self.gold_location = None\n",
        "\n",
        "        elif action == Action.SHOOT:\n",
        "            # Only the first time with an arrow should cost -10 and attempt a kill\n",
        "            if self.agent_has_arrow:\n",
        "                self.agent_has_arrow = False\n",
        "                reward += -10\n",
        "                if self.kill_attempt():  # sets wumpus_alive=False if hit\n",
        "                    scream = True\n",
        "            # If no arrow, no extra penalty/effect\n",
        "\n",
        "        elif action == Action.CLIMB:\n",
        "            # Only meaningful at the start cell (1,1)\n",
        "            if self.agent_location.is_location(Location(1, 1)):\n",
        "                if self.agent_has_gold:\n",
        "                    reward += 1000\n",
        "                    self.game_over = True\n",
        "                else:\n",
        "                    if self.allow_climb_without_gold:\n",
        "                        # End episode with just the step cost already applied\n",
        "                        self.game_over = True\n",
        "                    # else: climbing without gold is ignored\n",
        "\n",
        "        # ---------------------------\n",
        "        # Build Percept for this step\n",
        "        # ---------------------------\n",
        "        percept = Percept(\n",
        "            time_step=self.time_step,\n",
        "            bump=bump,\n",
        "            breeze=self.is_breeze(),\n",
        "            stench=self.is_stench(),\n",
        "            scream=scream,\n",
        "            glitter=self.is_glitter(),\n",
        "            reward=reward,\n",
        "            done=self.game_over\n",
        "        )\n",
        "        return percept\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # VISUALIZATION OF THE GAME STATE\n",
        "    # ---------------------------------------------------------------------\n",
        "    def visualize(self):\n",
        "        \"\"\"\n",
        "        Print a simple text grid showing the current world state.\n",
        "\n",
        "        Legend:\n",
        "            A→ A← A↑ A↓ : Agent and its facing direction\n",
        "            P           : Pit\n",
        "            W / w       : Wumpus (alive/dead)\n",
        "            G           : Gold\n",
        "\n",
        "        Coordinate system:\n",
        "            (1,1) is bottom-left; printed from the top row down to the bottom.\n",
        "        \"\"\"\n",
        "        for y in range(self.HEIGHT, 0, -1):  # print rows top→bottom\n",
        "            line = '|'\n",
        "            for x in range(1, self.WIDTH + 1):  # columns left→right\n",
        "                loc = Location(x, y)\n",
        "                cell_symbols = []  # dynamic list for whatever is in this cell\n",
        "\n",
        "                # Agent (shows letter A plus its facing arrow)\n",
        "                if self.is_agent_at(loc):\n",
        "                    cell_symbols.append('A' + self.agent_orientation.symbol())\n",
        "\n",
        "                # Pit\n",
        "                if self.is_pit_at(loc):\n",
        "                    cell_symbols.append('P')\n",
        "\n",
        "                # Wumpus (alive/dead)\n",
        "                if self.is_wumpus_at(loc):\n",
        "                    cell_symbols.append('W' if self.wumpus_alive else 'w')\n",
        "\n",
        "                # Gold\n",
        "                if self.is_gold_at(loc):\n",
        "                    cell_symbols.append('G')\n",
        "\n",
        "                # If cell empty, leave a few spaces for alignment\n",
        "                cell_str = ''.join(cell_symbols) if cell_symbols else '   '\n",
        "\n",
        "                line += f'{cell_str:4}|'  # pad each cell to uniform width\n",
        "            print(line)\n"
      ],
      "metadata": {
        "id": "MUMPy6tSrl_x"
      },
      "id": "MUMPy6tSrl_x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probabilistic Model Definition (Pomegranate)"
      ],
      "metadata": {
        "id": "6ao2DVmcpe_W"
      },
      "id": "6ao2DVmcpe_W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Funcitons"
      ],
      "metadata": {
        "id": "dsJSDHwZsiPu"
      },
      "id": "dsJSDHwZsiPu"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pomegranate==1.0.4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC-Btzutua5g",
        "outputId": "a825859a-2f45-4a1b-c37e-b95eddd0fb0c"
      },
      "id": "GC-Btzutua5g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pomegranate==1.0.4 in /usr/local/lib/python3.12/dist-packages (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.12/dist-packages (from pomegranate==1.0.4) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from pomegranate==1.0.4) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from pomegranate==1.0.4) (1.6.1)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from pomegranate==1.0.4) (2.9.0+cu126)\n",
            "Requirement already satisfied: apricot-select>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pomegranate==1.0.4) (0.6.1)\n",
            "Requirement already satisfied: networkx>=2.8.4 in /usr/local/lib/python3.12/dist-packages (from pomegranate==1.0.4) (3.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.12/dist-packages (from apricot-select>=0.6.1->pomegranate==1.0.4) (0.60.0)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.12/dist-packages (from apricot-select>=0.6.1->pomegranate==1.0.4) (4.67.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.12/dist-packages (from apricot-select>=0.6.1->pomegranate==1.0.4) (1.3.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.2->pomegranate==1.0.4) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.2->pomegranate==1.0.4) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->pomegranate==1.0.4) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.43.0->apricot-select>=0.6.1->pomegranate==1.0.4) (0.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->pomegranate==1.0.4) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.0->pomegranate==1.0.4) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import masked\n",
        "\n",
        "from pomegranate.distributions import Categorical, ConditionalCategorical\n",
        "from pomegranate.bayesian_network import BayesianNetwork\n"
      ],
      "metadata": {
        "id": "J3QrmE9Pv6YY"
      },
      "id": "J3QrmE9Pv6YY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Predicate:\n",
        "    \"\"\"\n",
        "    Small helper exactly like in the course notebook.\n",
        "\n",
        "    Represents a boolean predicate which is True with probability p\n",
        "    and False with probability 1-p. Encodes as [P(False), P(True)].\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, prob: float):\n",
        "        self.p = prob\n",
        "\n",
        "    def to_list(self) -> List[float]:\n",
        "        return [1.0 - self.p, self.p]\n",
        "\n",
        "    def to_categorical(self) -> Categorical:\n",
        "        return Categorical([self.to_list()])\n",
        "\n",
        "\n",
        "def all_cells(width: int, height: int) -> List[Tuple[int, int]]:\n",
        "    \"\"\"Return all (x, y) cells in a 1-based width×height grid.\"\"\"\n",
        "    return [(x, y) for x in range(1, width + 1) for y in range(1, height + 1)]\n",
        "\n",
        "\n",
        "def adjacent_cells(x: int, y: int, width: int, height: int) -> List[Tuple[int, int]]:\n",
        "    \"\"\"Return all 4-connected neighbours of (x, y) within the grid.\"\"\"\n",
        "    neighbours: List[Tuple[int, int]] = []\n",
        "    for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
        "        nx, ny = x + dx, y + dy\n",
        "        if 1 <= nx <= width and 1 <= ny <= height:\n",
        "            neighbours.append((nx, ny))\n",
        "    return neighbours\n",
        "\n",
        "\n",
        "def pit_var(x: int, y: int) -> str:\n",
        "    return f\"Pit_{x}_{y}\"\n",
        "\n",
        "\n",
        "def breeze_var(x: int, y: int) -> str:\n",
        "    return f\"Breeze_{x}_{y}\"\n",
        "\n",
        "\n",
        "def stench_var(x: int, y: int) -> str:\n",
        "    return f\"Stench_{x}_{y}\"\n",
        "\n",
        "\n",
        "def wumpus_loc_name() -> str:\n",
        "    return \"WumpusLocation\"\n",
        "\n",
        "\n",
        "def build_or_cases(num_parents: int) -> List:\n",
        "    \"\"\"\n",
        "    Build the nested probability tensor for a breeze-like predicate which is\n",
        "    True iff any of its binary pit parents is True.\n",
        "\n",
        "    Returns a nested list with shape (2, 2, ..., 2, 2):\n",
        "      - one 2 for each parent (False/True)\n",
        "      - last 2 for the child (False/True)\n",
        "    which will then be wrapped as [cases] to give the (1, ...) shape that\n",
        "    ConditionalCategorical expects.\n",
        "    \"\"\"\n",
        "\n",
        "    def rec(level: int, assignment: List[int]) -> List:\n",
        "        if level == num_parents:\n",
        "            any_pit = any(v == 1 for v in assignment)\n",
        "            p_true = 1.0 if any_pit else 0.0\n",
        "            return [1.0 - p_true, p_true]  # [P(False), P(True)]\n",
        "        # next level: 0 (False), 1 (True)\n",
        "        return [rec(level + 1, assignment + [0]), rec(level + 1, assignment + [1])]\n",
        "\n",
        "    return rec(0, [])"
      ],
      "metadata": {
        "id": "uo8nbGn-pzqu"
      },
      "id": "uo8nbGn-pzqu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pit / Breeze Model"
      ],
      "metadata": {
        "id": "ipIZRTXjsy29"
      },
      "id": "ipIZRTXjsy29"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_pit_breeze_model(\n",
        "    width: int = 4, height: int = 4, pit_prob: float = 0.2\n",
        ") -> BayesianNetwork:\n",
        "    \"\"\"\n",
        "    Build a Bayesian network for pits and breezes, following the style of\n",
        "    'Working with Pomegranate v1.04.ipynb'.\n",
        "\n",
        "    Design choices:\n",
        "      - 15 pit variables: all grid cells EXCEPT (1,1). Start is always safe.\n",
        "      - 16 breeze variables: one per cell.\n",
        "      - Pits are independent with prior:\n",
        "          Pit(x,y) ~ Bernoulli(pit_prob) for (x,y) != (1,1)\n",
        "      - Each Breeze(x,y) is True iff any adjacent pit is True.\n",
        "        Encoded as a ConditionalCategorical with OR semantics over parent pits.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Pit distributions (no pit at (1,1))\n",
        "    pit_dists: Dict[Tuple[int, int], Categorical] = {}\n",
        "    for x, y in all_cells(width, height):\n",
        "        if (x, y) == (1, 1):\n",
        "            continue  # start cell is always safe; no pit variable\n",
        "        pit_dists[(x, y)] = Predicate(pit_prob).to_categorical()\n",
        "\n",
        "    # 2) Breeze distributions\n",
        "    breeze_dists: Dict[Tuple[int, int], Categorical | ConditionalCategorical] = {}\n",
        "\n",
        "    for x, y in all_cells(width, height):\n",
        "        # Parent pits for this breeze: all adjacent cells that have a pit variable\n",
        "        parent_cells = [\n",
        "            (nx, ny)\n",
        "            for (nx, ny) in adjacent_cells(x, y, width, height)\n",
        "            if (nx, ny) in pit_dists\n",
        "        ]\n",
        "        num_parents = len(parent_cells)\n",
        "\n",
        "        if num_parents == 0:\n",
        "            # Degenerate case (e.g., 1x1 world) → no breeze ever.\n",
        "            breeze_dists[(x, y)] = Predicate(0.0).to_categorical()\n",
        "        else:\n",
        "            cases = build_or_cases(num_parents)\n",
        "            # Wrap as [cases] to give shape (1, 2, 2, ..., 2)\n",
        "            breeze_dists[(x, y)] = ConditionalCategorical([cases])\n",
        "\n",
        "    # 3) Build variables list and edges\n",
        "    variables: List[Categorical | ConditionalCategorical] = []\n",
        "    edges: List[Tuple[Categorical | ConditionalCategorical, ConditionalCategorical]] = []\n",
        "    index_by_name: Dict[str, int] = {}\n",
        "\n",
        "    # Add all pits first, in a consistent order\n",
        "    for x, y in all_cells(width, height):\n",
        "        if (x, y) == (1, 1):\n",
        "            continue\n",
        "        name = pit_var(x, y)\n",
        "        dist = pit_dists[(x, y)]\n",
        "        index_by_name[name] = len(variables)\n",
        "        variables.append(dist)\n",
        "\n",
        "    # Then all breezes\n",
        "    for x, y in all_cells(width, height):\n",
        "        name = breeze_var(x, y)\n",
        "        dist = breeze_dists[(x, y)]\n",
        "        index_by_name[name] = len(variables)\n",
        "        variables.append(dist)\n",
        "\n",
        "    # Now define edges: Pit -> Breeze whenever pit cell is adjacent\n",
        "    for x, y in all_cells(width, height):\n",
        "        breeze_dist = breeze_dists[(x, y)]\n",
        "        for nx, ny in adjacent_cells(x, y, width, height):\n",
        "            if (nx, ny) in pit_dists:\n",
        "                edges.append((pit_dists[(nx, ny)], breeze_dist))\n",
        "\n",
        "    pits_model = BayesianNetwork(variables, edges)\n",
        "\n",
        "    # Attach helper metadata for later use in inference\n",
        "    pits_model.variable_indices = index_by_name\n",
        "    pits_model.num_variables = len(variables)\n",
        "\n",
        "    return pits_model"
      ],
      "metadata": {
        "id": "PCMN6PnMGAyZ"
      },
      "id": "PCMN6PnMGAyZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wumpus / Stench Model"
      ],
      "metadata": {
        "id": "Tosm6Ehss_mK"
      },
      "id": "Tosm6Ehss_mK"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_wumpus_stench_model(width: int = 4, height: int = 4) -> BayesianNetwork:\n",
        "    \"\"\"\n",
        "    Build a Bayesian network for the Wumpus and stenches.\n",
        "\n",
        "    Design:\n",
        "      - One Categorical for WumpusLocation with 15 categories, one for each\n",
        "        non-start cell (all cells except (1,1)), uniform prior.\n",
        "      - 16 ConditionalCategorical nodes for stenches, one per cell.\n",
        "        Each Stench(x,y) is True iff Wumpus is in a 4-neighbour cell of (x,y).\n",
        "    \"\"\"\n",
        "\n",
        "    # Enumerate possible Wumpus locations (exclude start cell)\n",
        "    wumpus_positions: List[Tuple[int, int]] = [\n",
        "        (x, y) for (x, y) in all_cells(width, height) if (x, y) != (1, 1)\n",
        "    ]\n",
        "    num_locations = len(wumpus_positions)\n",
        "\n",
        "    # 1) Wumpus prior: uniform over 15 locations\n",
        "    wumpus_probs = [1.0 / num_locations] * num_locations\n",
        "    wumpus_dist = Categorical([wumpus_probs])\n",
        "\n",
        "    # 2) Stench conditional distributions\n",
        "    stench_dists: Dict[Tuple[int, int], ConditionalCategorical] = {}\n",
        "\n",
        "    for x, y in all_cells(width, height):\n",
        "        # For this cell, compute P(Stench | WumpusLocation = each loc)\n",
        "        rows: List[List[float]] = []\n",
        "        adj_cells = set(adjacent_cells(x, y, width, height))\n",
        "        for (wx, wy) in wumpus_positions:\n",
        "            is_adjacent = (wx, wy) in adj_cells\n",
        "            p_true = 1.0 if is_adjacent else 0.0\n",
        "            rows.append([1.0 - p_true, p_true])  # [P(False), P(True)]\n",
        "\n",
        "        # probs shape: (1, num_locations, 2)\n",
        "        probs = [rows]\n",
        "        stench_dists[(x, y)] = ConditionalCategorical(probs)\n",
        "\n",
        "    # 3) Build variables and edges\n",
        "    variables: List[Categorical | ConditionalCategorical] = []\n",
        "    edges: List[Tuple[Categorical, ConditionalCategorical]] = []\n",
        "    index_by_name: Dict[str, int] = {}\n",
        "\n",
        "    # WumpusLocation first\n",
        "    index_by_name[wumpus_loc_name()] = 0\n",
        "    variables.append(wumpus_dist)\n",
        "\n",
        "    # Then all stenches\n",
        "    for x, y in all_cells(width, height):\n",
        "        name = stench_var(x, y)\n",
        "        dist = stench_dists[(x, y)]\n",
        "        index_by_name[name] = len(variables)\n",
        "        variables.append(dist)\n",
        "        edges.append((wumpus_dist, dist))\n",
        "\n",
        "    wumpus_model = BayesianNetwork(variables, edges)\n",
        "\n",
        "    # Metadata for inference\n",
        "    wumpus_model.variable_indices = index_by_name\n",
        "    wumpus_model.num_variables = len(variables)\n",
        "    wumpus_model.wumpus_positions = wumpus_positions  # list of (x,y) in index order\n",
        "\n",
        "    return wumpus_model"
      ],
      "metadata": {
        "id": "yLqEKnACGBT9"
      },
      "id": "yLqEKnACGBT9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference helpers for Pit/Breeze and Wumpus/Stench Models"
      ],
      "metadata": {
        "id": "Vcb4AFpxx-0X"
      },
      "id": "Vcb4AFpxx-0X"
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_pit_posteriors(\n",
        "    pit_model: BayesianNetwork,\n",
        "    width: int,\n",
        "    height: int,\n",
        "    breeze_history: Dict[Tuple[int, int], bool],\n",
        ") -> Dict[Tuple[int, int], float]:\n",
        "    \"\"\"\n",
        "    Given:\n",
        "      - a baked pit/breeze BayesianNetwork (pits_model)\n",
        "      - grid size\n",
        "      - observed breezes in some cells (True/False)\n",
        "\n",
        "    Return:\n",
        "      - pit_probs[(x,y)] = P(Pit_x_y = True | all observed breezes)\n",
        "\n",
        "    Follows the pattern from the course notebook:\n",
        "      - Build X with -1 for unknown, 0/1 for observed variables\n",
        "      - Use a MaskedTensor for predict_proba\n",
        "    \"\"\"\n",
        "    n_vars = pit_model.num_variables\n",
        "    X = torch.full((1, n_vars), -1, dtype=torch.long)\n",
        "    mask = torch.zeros((1, n_vars), dtype=torch.bool)\n",
        "\n",
        "    # Only breezes are used as evidence here (you could also encode known-safe pits as 0)\n",
        "    for (x, y), has_breeze in breeze_history.items():\n",
        "        name = breeze_var(x, y)\n",
        "        idx = pit_model.variable_indices[name]\n",
        "        X[0, idx] = 1 if has_breeze else 0\n",
        "        mask[0, idx] = True\n",
        "\n",
        "    X_masked = masked.MaskedTensor(X, mask=mask)\n",
        "    posteriors = pit_model.predict_proba(X_masked)\n",
        "\n",
        "    pit_probs: Dict[Tuple[int, int], float] = {}\n",
        "\n",
        "    for x, y in all_cells(width, height):\n",
        "        if (x, y) == (1, 1):\n",
        "            # Start cell cannot be a pit\n",
        "            pit_probs[(x, y)] = 0.0\n",
        "            continue\n",
        "        name = pit_var(x, y)\n",
        "        idx = pit_model.variable_indices[name]\n",
        "        # posteriors[idx] is a tensor of shape (1, 2): [P(False), P(True)]\n",
        "        probs_tensor = posteriors[idx]\n",
        "        p_true = float(probs_tensor[0, 1].item())\n",
        "        pit_probs[(x, y)] = p_true\n",
        "\n",
        "    return pit_probs\n",
        "\n",
        "\n",
        "def infer_wumpus_posteriors(\n",
        "    wumpus_model: BayesianNetwork,\n",
        "    width: int,\n",
        "    height: int,\n",
        "    stench_history: Dict[Tuple[int, int], bool],\n",
        "    wumpus_dead: bool,\n",
        ") -> Dict[Tuple[int, int], float]:\n",
        "    \"\"\"\n",
        "    Given:\n",
        "      - a baked Wumpus/stench BayesianNetwork (wumpus_model)\n",
        "      - grid size\n",
        "      - observed stenches in some cells (True/False)\n",
        "      - flag wumpus_dead (if we have heard a scream and know it's dead)\n",
        "\n",
        "    Return:\n",
        "      - wumpus_probs[(x,y)] = P(Wumpus is at (x,y) | evidence)\n",
        "        or all zeros if wumpus_dead is True.\n",
        "    \"\"\"\n",
        "    wumpus_probs: Dict[Tuple[int, int], float] = {}\n",
        "\n",
        "    if wumpus_dead:\n",
        "        # Once the Wumpus is dead, its hazard contribution is zero.\n",
        "        for x, y in all_cells(width, height):\n",
        "            wumpus_probs[(x, y)] = 0.0\n",
        "        return wumpus_probs\n",
        "\n",
        "    n_vars = wumpus_model.num_variables\n",
        "    X = torch.full((1, n_vars), -1, dtype=torch.long)\n",
        "    mask = torch.zeros((1, n_vars), dtype=torch.bool)\n",
        "\n",
        "    # Evidence: stenches\n",
        "    for (x, y), has_stench in stench_history.items():\n",
        "        name = stench_var(x, y)\n",
        "        idx = wumpus_model.variable_indices[name]\n",
        "        X[0, idx] = 1 if has_stench else 0\n",
        "        mask[0, idx] = True\n",
        "\n",
        "    X_masked = masked.MaskedTensor(X, mask=mask)\n",
        "    posteriors = wumpus_model.predict_proba(X_masked)\n",
        "\n",
        "    # Posterior over WumpusLocation\n",
        "    w_name = wumpus_loc_name()\n",
        "    w_idx = wumpus_model.variable_indices[w_name]\n",
        "    w_tensor = posteriors[w_idx]  # shape (1, num_locations)\n",
        "    w_vec = w_tensor[0]\n",
        "\n",
        "    # Map location indices back to (x,y)\n",
        "    positions: List[Tuple[int, int]] = wumpus_model.wumpus_positions\n",
        "    for loc_idx, (x, y) in enumerate(positions):\n",
        "        wumpus_probs[(x, y)] = float(w_vec[loc_idx].item())\n",
        "\n",
        "    # Start cell cannot contain the Wumpus\n",
        "    if (1, 1) not in wumpus_probs:\n",
        "        wumpus_probs[(1, 1)] = 0.0\n",
        "\n",
        "    return wumpus_probs\n",
        "\n",
        "\n",
        "def compute_safety_from_hazards(\n",
        "    pit_probs: Dict[Tuple[int, int], float],\n",
        "    wumpus_probs: Dict[Tuple[int, int], float],\n",
        ") -> Dict[Tuple[int, int], float]:\n",
        "    \"\"\"\n",
        "    Combine pit and Wumpus probabilities into a safety score:\n",
        "\n",
        "      P(safe) = (1 - P(pit)) * (1 - P(wumpus))\n",
        "\n",
        "    for each cell (x, y).\n",
        "    \"\"\"\n",
        "    safety: Dict[Tuple[int, int], float] = {}\n",
        "\n",
        "    all_cells_set = set(pit_probs.keys()) | set(wumpus_probs.keys())\n",
        "    for cell in all_cells_set:\n",
        "        p_pit = pit_probs.get(cell, 0.0)\n",
        "        p_w = wumpus_probs.get(cell, 0.0)\n",
        "        safety[cell] = (1.0 - p_pit) * (1.0 - p_w)\n",
        "\n",
        "    return safety"
      ],
      "metadata": {
        "id": "qGM2-gEsGSqV"
      },
      "id": "qGM2-gEsGSqV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PGM Sanity Testing\n"
      ],
      "metadata": {
        "id": "ITsv4ozTfgoj"
      },
      "id": "ITsv4ozTfgoj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity-check the Pit/Breeze model (tiny world)"
      ],
      "metadata": {
        "id": "LIJzEqnlfs-m"
      },
      "id": "LIJzEqnlfs-m"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiny sanity-check for pits_model, like the notebook example\n",
        "\n",
        "# Build 4x4 model but we’ll only care about (1,2), (2,1), (1,1)\n",
        "pits_model = build_pit_breeze_model(width=4, height=4, pit_prob=0.2)\n",
        "\n",
        "print(\"Variables in pits_model:\")\n",
        "print(pits_model.variable_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKB8mHiofzwN",
        "outputId": "a91dcd6a-79dd-40d8-c3c8-207553d114f4"
      },
      "id": "bKB8mHiofzwN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables in pits_model:\n",
            "{'Pit_1_2': 0, 'Pit_1_3': 1, 'Pit_1_4': 2, 'Pit_2_1': 3, 'Pit_2_2': 4, 'Pit_2_3': 5, 'Pit_2_4': 6, 'Pit_3_1': 7, 'Pit_3_2': 8, 'Pit_3_3': 9, 'Pit_3_4': 10, 'Pit_4_1': 11, 'Pit_4_2': 12, 'Pit_4_3': 13, 'Pit_4_4': 14, 'Breeze_1_1': 15, 'Breeze_1_2': 16, 'Breeze_1_3': 17, 'Breeze_1_4': 18, 'Breeze_2_1': 19, 'Breeze_2_2': 20, 'Breeze_2_3': 21, 'Breeze_2_4': 22, 'Breeze_3_1': 23, 'Breeze_3_2': 24, 'Breeze_3_3': 25, 'Breeze_3_4': 26, 'Breeze_4_1': 27, 'Breeze_4_2': 28, 'Breeze_4_3': 29, 'Breeze_4_4': 30}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: just test breezes at (1,1)\n",
        "breeze_history_cases = {\n",
        "    \"Q1_no_breeze\": {(1, 1): False},\n",
        "    \"Q2_yes_breeze\": {(1, 1): True},\n",
        "    \"Q3_unknown_breeze\": {},  # no evidence\n",
        "}\n",
        "\n",
        "for label, bh in breeze_history_cases.items():\n",
        "    pit_probs = infer_pit_posteriors(pits_model, width=4, height=4, breeze_history=bh)\n",
        "    print(f\"\\n{label}:\")\n",
        "    print(\"P(Pit_1_2 = True):\", pit_probs[(1, 2)])\n",
        "    print(\"P(Pit_2_1 = True):\", pit_probs[(2, 1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8zq6goIf2WR",
        "outputId": "de41bf3e-239a-441f-9cf0-2653d0830d94"
      },
      "id": "u8zq6goIf2WR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q1_no_breeze:\n",
            "P(Pit_1_2 = True): 0.0\n",
            "P(Pit_2_1 = True): 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-14819521.py:31: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  X_masked = masked.MaskedTensor(X, mask=mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q2_yes_breeze:\n",
            "P(Pit_1_2 = True): 0.5555555820465088\n",
            "P(Pit_2_1 = True): 0.5555555820465088\n",
            "\n",
            "Q3_unknown_breeze:\n",
            "P(Pit_1_2 = True): 0.20000000298023224\n",
            "P(Pit_2_1 = True): 0.20000000298023224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity-check the Wumpus/Stench model"
      ],
      "metadata": {
        "id": "QbF5E3u2f5sw"
      },
      "id": "QbF5E3u2f5sw"
    },
    {
      "cell_type": "code",
      "source": [
        "wumpus_model = build_wumpus_stench_model(width=4, height=4)\n",
        "\n",
        "print(\"Variables in wumpus_model:\")\n",
        "print(wumpus_model.variable_indices)\n",
        "print(\"Wumpus positions:\", wumpus_model.wumpus_positions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CobXhpTSf9dt",
        "outputId": "890914c5-4bb5-400a-f844-6fc826b75ac3"
      },
      "id": "CobXhpTSf9dt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables in wumpus_model:\n",
            "{'WumpusLocation': 0, 'Stench_1_1': 1, 'Stench_1_2': 2, 'Stench_1_3': 3, 'Stench_1_4': 4, 'Stench_2_1': 5, 'Stench_2_2': 6, 'Stench_2_3': 7, 'Stench_2_4': 8, 'Stench_3_1': 9, 'Stench_3_2': 10, 'Stench_3_3': 11, 'Stench_3_4': 12, 'Stench_4_1': 13, 'Stench_4_2': 14, 'Stench_4_3': 15, 'Stench_4_4': 16}\n",
            "Wumpus positions: [(1, 2), (1, 3), (1, 4), (2, 1), (2, 2), (2, 3), (2, 4), (3, 1), (3, 2), (3, 3), (3, 4), (4, 1), (4, 2), (4, 3), (4, 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# No stenches → uniform posterior\n",
        "stench_history = {}\n",
        "w_probs = infer_wumpus_posteriors(\n",
        "    wumpus_model,\n",
        "    width=4,\n",
        "    height=4,\n",
        "    stench_history=stench_history,\n",
        "    wumpus_dead=False,\n",
        ")\n",
        "\n",
        "# Excluding (1,1), all others should be ~1/15\n",
        "print(\"Sum of P(Wumpus):\", sum(w_probs.values()))\n",
        "print(\"Example cells:\", {pos: w_probs[pos] for pos in list(w_probs.keys())[:5]})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08luhWNOgCni",
        "outputId": "3a95858d-9871-46b9-af8b-223324751627"
      },
      "id": "08luhWNOgCni",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of P(Wumpus): 0.9999999403953552\n",
            "Example cells: {(1, 2): 0.06666666269302368, (1, 3): 0.06666666269302368, (1, 4): 0.06666666269302368, (2, 1): 0.06666666269302368, (2, 2): 0.06666666269302368}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-14819521.py:88: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  X_masked = masked.MaskedTensor(X, mask=mask)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One stench → only neighbours have non-zero probability\n",
        "stench_history = {(2, 1): True}\n",
        "w_probs = infer_wumpus_posteriors(\n",
        "    wumpus_model,\n",
        "    width=4,\n",
        "    height=4,\n",
        "    stench_history=stench_history,\n",
        "    wumpus_dead=False,\n",
        ")\n",
        "\n",
        "print(\"Cells with non-negligible probability:\")\n",
        "for (x, y), p in w_probs.items():\n",
        "    if p > 1e-6:\n",
        "        print((x, y), \":\", p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLr6J9RIgGyv",
        "outputId": "62bb2572-8933-41fc-cf3d-7f5e75d2a086"
      },
      "id": "BLr6J9RIgGyv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cells with non-negligible probability:\n",
            "(2, 2) : 0.5\n",
            "(3, 1) : 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-14819521.py:88: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  X_masked = masked.MaskedTensor(X, mask=mask)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent definition"
      ],
      "metadata": {
        "id": "YxuqeEnrv5U2"
      },
      "id": "YxuqeEnrv5U2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Planner Definition"
      ],
      "metadata": {
        "id": "QCssoHEswACL"
      },
      "id": "QCssoHEswACL"
    },
    {
      "cell_type": "code",
      "source": [
        "State = Tuple[int, int, int]  # (x, y, d) with x,y 1-based; d in {0..3}\n",
        "\n",
        "# Define DX and DY for directional movement\n",
        "DX = [1, 0, -1, 0]  # E, S, W, N\n",
        "DY = [0, -1, 0, 1]  # E, S, W, N\n",
        "\n",
        "# Helper functions for turning\n",
        "def dir_left(d: int) -> int:\n",
        "    \"\"\"Turn counter-clockwise (E → N → W → S → E).\"\"\"\n",
        "    return (d - 1) % 4\n",
        "\n",
        "def dir_right(d: int) -> int:\n",
        "    \"\"\"Turn clockwise (E → S → W → N → E).\"\"\"\n",
        "    return (d + 1) % 4\n",
        "\n",
        "def bfs_shortest_actions(\n",
        "    start: State,\n",
        "    goal_cell: Tuple[int, int],\n",
        "    safe_cells: Set[Tuple[int, int]],\n",
        "    width: int,\n",
        "    height: int,\n",
        ") -> Optional[List[str]]:\n",
        "    \"\"\"\n",
        "    Shortest path (unit cost) in orientation-augmented space.\n",
        "    Actions are: \"TurnLeft\", \"TurnRight\", \"Forward\".\n",
        "    Forward permitted only if the destination cell is in safe_cells and in-bounds.\n",
        "    \"\"\"\n",
        "    sx, sy, sd = start\n",
        "    if (sx, sy) == goal_cell:\n",
        "        return []\n",
        "\n",
        "    def in_bounds(x: int, y: int) -> bool:\n",
        "        return 1 <= x <= width and 1 <= y <= height\n",
        "\n",
        "    parent: Dict[State, Tuple[State, str]] = {}\n",
        "    seen: Set[State] = {(sx, sy, sd)}\n",
        "    q: Deque[State] = deque([(sx, sy, sd)])\n",
        "\n",
        "    while q:\n",
        "        x, y, d = q.popleft()\n",
        "\n",
        "        # TurnLeft\n",
        "        nl = (x, y, dir_left(d))\n",
        "        if nl not in seen:\n",
        "            seen.add(nl); parent[nl] = ((x, y, d), \"TurnLeft\")\n",
        "            if (x, y) == goal_cell:\n",
        "                return _reconstruct_actions(parent, nl)\n",
        "            q.append(nl)\n",
        "\n",
        "        # TurnRight\n",
        "        nr = (x, y, dir_right(d))\n",
        "        if nr not in seen:\n",
        "            seen.add(nr); parent[nr] = ((x, y, d), \"TurnRight\")\n",
        "            if (x, y) == goal_cell:\n",
        "                return _reconstruct_actions(parent, nr)\n",
        "            q.append(nr)\n",
        "\n",
        "        # Forward (only into known-safe)\n",
        "        fx, fy = x + DX[d], y + DY[d]\n",
        "        if in_bounds(fx, fy) and (fx, fy) in safe_cells:\n",
        "            nf = (fx, fy, d)\n",
        "            if nf not in seen:\n",
        "                seen.add(nf); parent[nf] = ((x, y, d), \"Forward\")\n",
        "                if (fx, fy) == goal_cell:\n",
        "                    return _reconstruct_actions(parent, nf)\n",
        "                q.append(nf)\n",
        "\n",
        "    return None  # no route through known-safe cells\n",
        "\n",
        "def _reconstruct_actions(\n",
        "    parent: Dict[State, Tuple[State, str]],\n",
        "    goal: State\n",
        ") -> List[str]:\n",
        "    actions: List[str] = []\n",
        "    cur: Optional[State] = goal\n",
        "    while cur in parent:\n",
        "        prev, a = parent[cur]\n",
        "        actions.append(a)\n",
        "        cur = prev\n",
        "    actions.reverse()\n",
        "    return actions"
      ],
      "metadata": {
        "id": "dub8EHIhwHMo"
      },
      "id": "dub8EHIhwHMo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NaiveAgent Definition"
      ],
      "metadata": {
        "id": "plF3HE10Vqks"
      },
      "id": "plF3HE10Vqks"
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveAgent:\n",
        "    \"\"\"\n",
        "    A naive agent that selects random actions and interacts with the Environment.\n",
        "    It uses the updated Environment interface supporting dynamic grid sizes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, width: int = 4, height: int = 4,\n",
        "                 pit_prob: float = 0.2, allow_climb_without_gold: bool = True,\n",
        "                 seed: int = None):\n",
        "        \"\"\"\n",
        "        Initialize the NaiveAgent with optional environment parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        width : int\n",
        "            Width of the grid (default: 4)\n",
        "        height : int\n",
        "            Height of the grid (default: 4)\n",
        "        pit_prob : float\n",
        "            Probability that a non-start cell contains a pit (default: 0.2)\n",
        "        allow_climb_without_gold : bool\n",
        "            Whether climbing without gold ends the episode (default: True)\n",
        "        seed : int, optional\n",
        "            Random seed for reproducibility (default: None)\n",
        "        \"\"\"\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.pit_prob = pit_prob\n",
        "        self.allow_climb_without_gold = allow_climb_without_gold\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "    def choose_action(self):\n",
        "        \"\"\"Return a randomly chosen action from the Action enum.\"\"\"\n",
        "        return random.choice(list(Action))\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run a full episode of random actions until the game ends.\"\"\"\n",
        "        env = Environment()\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        # Initialize the environment using the new parameterized interface\n",
        "        percept = env.init(\n",
        "            width=self.width,\n",
        "            height=self.height,\n",
        "            pit_prob=self.pit_prob,\n",
        "            allow_climb_without_gold=self.allow_climb_without_gold\n",
        "        )\n",
        "\n",
        "        # Main loop: random actions until terminal state\n",
        "        while not percept.done:\n",
        "            env.visualize()\n",
        "            print('Percept:', percept)\n",
        "            action = self.choose_action()\n",
        "            print('\\nAction:', action, '\\n')\n",
        "            percept = env.step(action)\n",
        "            cumulative_reward += percept.reward\n",
        "\n",
        "        # Final visualization and summary\n",
        "        env.visualize()\n",
        "        print('Percept:', percept)\n",
        "        print('Cumulative reward:', cumulative_reward)\n"
      ],
      "metadata": {
        "id": "nKR52kQ2wDLe"
      },
      "id": "nKR52kQ2wDLe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = NaiveAgent()\n",
        "for _ in range(6):\n",
        "    print(agent.choose_action())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzXGRoR_W5z8",
        "outputId": "79a9392d-2b73-47f1-bbf2-ec55f70cd3c0"
      },
      "id": "OzXGRoR_W5z8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action.RIGHT\n",
            "Action.LEFT\n",
            "Action.FORWARD\n",
            "Action.CLIMB\n",
            "Action.FORWARD\n",
            "Action.SHOOT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MovePlanningAgent Definition"
      ],
      "metadata": {
        "id": "d40d2U7QwJx6"
      },
      "id": "d40d2U7QwJx6"
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MovePlanningAgent:\n",
        "    width: int = 4\n",
        "    height: int = 4\n",
        "    allow_climb_without_gold: bool = True\n",
        "    pit_prob: float = 0.2\n",
        "\n",
        "    # runtime state\n",
        "    x: int = 1\n",
        "    y: int = 1\n",
        "    d: int = 0  # 0:E, 1:S, 2:W, 3:N\n",
        "    has_gold: bool = False\n",
        "    visited_safe: Set[Tuple[int, int]] = field(default_factory=lambda: {(1, 1)})\n",
        "    plan: Deque[str] = field(default_factory=deque)\n",
        "    rng: random.Random = field(default_factory=random.Random)\n",
        "    cumulative_reward: int = 0\n",
        "\n",
        "    # environment is injected at run()\n",
        "    env: object = None\n",
        "\n",
        "    def run(self, Environment, Action):\n",
        "        \"\"\"Assumes your Environment has .init(pit_prob, allowClimbWithoutGold), .step(action), .visualize().\"\"\"\n",
        "        # initialize episode\n",
        "        self.env = Environment()\n",
        "\n",
        "        percept = self.env.init(\n",
        "              width=self.width,\n",
        "              height=self.height,\n",
        "              pit_prob=self.pit_prob,\n",
        "              allow_climb_without_gold=self.allow_climb_without_gold,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.x, self.y, self.d = 1, 1, 0\n",
        "        self.has_gold = False\n",
        "        self.visited_safe = {(1, 1)}\n",
        "        self.plan.clear()\n",
        "        self.cumulative_reward = 0\n",
        "\n",
        "\n",
        "        while not percept.done:\n",
        "              # 1) Show board and current percept (same as NaiveAgent)\n",
        "              self.env.visualize()\n",
        "              print('Percept:', percept)\n",
        "\n",
        "              # 2) Deterministic reaction to glitter\n",
        "              if percept.glitter and not self.has_gold:\n",
        "                  print('\\nAction:', Action.GRAB, '\\n')\n",
        "                  percept = self.env.step(Action.GRAB)\n",
        "                  self.cumulative_reward += percept.reward\n",
        "                  self.has_gold = True\n",
        "                  if not percept.done:\n",
        "                      self.visited_safe.add((self.x, self.y))\n",
        "                  # plan shortest safe path to start\n",
        "                  self.plan = deque(bfs_shortest_actions(\n",
        "                      (self.x, self.y, self.d), (1, 1), self.visited_safe, self.width, self.height\n",
        "                  ) or [])\n",
        "                  continue\n",
        "\n",
        "              # 3) If executing a plan, take the next planned action\n",
        "              if self.plan:\n",
        "                  action = self._action_from_label(self.plan.popleft(), Action)\n",
        "                  print('\\nAction:', action, '\\n')\n",
        "                  # _act_and_update() will call env.step() and update pose/safe set\n",
        "                  percept = self._act_and_update(action)\n",
        "\n",
        "                  # If plan finished at start with gold, climb out\n",
        "                  if not self.plan and self.has_gold and (self.x, self.y) == (1, 1) and not percept.done:\n",
        "                      print('\\nAction:', Action.CLIMB, '\\n')\n",
        "                      percept = self._act_and_update(Action.CLIMB)\n",
        "                  continue\n",
        "\n",
        "              # 4) Otherwise: explore (no random Grab/Climb)\n",
        "              action = self.rng.choice([Action.FORWARD, Action.LEFT, Action.RIGHT, Action.SHOOT])\n",
        "              print('\\nAction:', action, '\\n')\n",
        "              percept = self._act_and_update(action)\n",
        "\n",
        "\n",
        "        # final board\n",
        "        try: self.env.visualize()\n",
        "        except Exception: pass\n",
        "\n",
        "        print(\"Percept:\", percept)\n",
        "        print(\"Cumulative reward:\", self.cumulative_reward)\n",
        "        return self.cumulative_reward\n",
        "\n",
        "    # ---- helpers ----\n",
        "    def _act_and_update(self, action):\n",
        "        \"\"\"Dispatch action to env, update pose and safe set based on percept.\"\"\"\n",
        "        p = self.env.step(action)\n",
        "        self.cumulative_reward += p.reward\n",
        "\n",
        "        # Update heading/position consistent with Assignment 1 semantics\n",
        "        name = getattr(action, \"name\", str(action))\n",
        "        if name == \"LEFT\":\n",
        "            self.d = dir_left(self.d)\n",
        "        elif name == \"RIGHT\":\n",
        "            self.d = dir_right(self.d)\n",
        "        elif name == \"FORWARD\":\n",
        "            # Only advance on no-bump\n",
        "            if not p.bump:\n",
        "                self.x += DX[self.d]\n",
        "                self.y += DY[self.d]\n",
        "\n",
        "        if not p.done:\n",
        "            self.visited_safe.add((self.x, self.y))\n",
        "        return p\n",
        "\n",
        "    @staticmethod\n",
        "    def _action_from_label(label: str, Action):\n",
        "        return {\n",
        "            \"Forward\": Action.FORWARD,\n",
        "            \"TurnLeft\": Action.LEFT,\n",
        "            \"TurnRight\": Action.RIGHT,\n",
        "        }[label]"
      ],
      "metadata": {
        "id": "XtojssTtwRfi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XtojssTtwRfi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ProbAgent Definition"
      ],
      "metadata": {
        "id": "bHZPlDd80SZ9"
      },
      "id": "bHZPlDd80SZ9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Orientation indices: 0 = E, 1 = S, 2 = W, 3 = N\n",
        "# We map them to (dx, dy) steps in the grid.\n",
        "# Assumption: x increases to the right (east), y increases upward (north).\n",
        "ORIENTATION_DELTAS = {\n",
        "    Orientation.E.value: (1, 0),   # east\n",
        "    Orientation.S.value: (0, -1),  # south\n",
        "    Orientation.W.value: (-1, 0),  # west\n",
        "    Orientation.N.value: (0, 1),   # north\n",
        "}"
      ],
      "metadata": {
        "id": "HnI4vYbjU0-d"
      },
      "id": "HnI4vYbjU0-d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProbAgent(MovePlanningAgent):\n",
        "    \"\"\"\n",
        "    Probabilistic Wumpus World agent.\n",
        "\n",
        "    Extends MovePlanningAgent by:\n",
        "      - Maintaining a belief state over pits and the Wumpus using\n",
        "        Bayesian networks (pomegranate v1.0.4).\n",
        "      - Using percept history (breezes, stenches, scream) to update\n",
        "        hazard probabilities.\n",
        "      - Choosing actions based on safest cells instead of random exploration.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        width: int = 4,\n",
        "        height: int = 4,\n",
        "        pit_prob: float = 0.2,\n",
        "        allow_climb_without_gold: bool = True,\n",
        "    ):\n",
        "        # Initialize MovePlanningAgent base (dataclass-generated __init__)\n",
        "        super().__init__(\n",
        "            width=width,\n",
        "            height=height,\n",
        "            allow_climb_without_gold=allow_climb_without_gold,\n",
        "            pit_prob=pit_prob,\n",
        "        )\n",
        "\n",
        "        # Store grid + prior parameters for convenience\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.pit_prob = pit_prob\n",
        "\n",
        "        # Build Bayesian models once per agent/episode\n",
        "        self.pit_model = build_pit_breeze_model(width, height, pit_prob)\n",
        "        self.wumpus_model = build_wumpus_stench_model(width, height)\n",
        "\n",
        "        # Percept history (evidence)\n",
        "        self.breeze_history: Dict[Tuple[int, int], bool] = {}\n",
        "        self.stench_history: Dict[Tuple[int, int], bool] = {}\n",
        "\n",
        "        # Wumpus status\n",
        "        self.heard_scream: bool = False\n",
        "        self.wumpus_dead: bool = False\n",
        "\n",
        "        # Agent's personal inventory\n",
        "        self.has_arrow: bool = True  # Initialize has_arrow here\n",
        "\n",
        "        # Tracking: was the arrow used during this episode? (for evaluation stats)\n",
        "        self.arrow_used_this_episode: bool = False\n",
        "\n",
        "        # Current posterior beliefs and safety (filled by update_beliefs)\n",
        "        self.pit_probs: Dict[Tuple[int, int], float] = {}\n",
        "        self.wumpus_probs: Dict[Tuple[int, int], float] = {}\n",
        "        self.safety: Dict[Tuple[int, int], float] = {}\n",
        "\n",
        "        # Initialize to prior beliefs (no evidence yet)\n",
        "        self._initialize_prior_beliefs()\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Belief initialization and update\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    def _initialize_prior_beliefs(self) -> None:\n",
        "        \"\"\"\n",
        "        Initialize pit_probs, wumpus_probs, and safety from the priors,\n",
        "        before any evidence is observed.\n",
        "        \"\"\"\n",
        "        # Pit priors: 0 at (1,1), pit_prob elsewhere\n",
        "        for x, y in all_cells(self.width, self.height):\n",
        "            if (x, y) == (1, 1):\n",
        "                self.pit_probs[(x, y)] = 0.0\n",
        "            else:\n",
        "                self.pit_probs[(x, y)] = self.pit_prob\n",
        "\n",
        "        # Wumpus priors: 0 at (1,1), uniform over the remaining cells\n",
        "        num_cells = self.width * self.height\n",
        "        num_valid = num_cells - 1  # exclude (1,1)\n",
        "        for x, y in all_cells(self.width, self.height):\n",
        "            if (x, y) == (1, 1):\n",
        "                self.wumpus_probs[(x, y)] = 0.0\n",
        "            else:\n",
        "                self.wumpus_probs[(x, y)] = 1.0 / num_valid\n",
        "\n",
        "        # Combine into initial safety scores\n",
        "        self.safety = compute_safety_from_hazards(self.pit_probs, self.wumpus_probs)\n",
        "\n",
        "    def update_beliefs(self, percept: Percept) -> None:\n",
        "        \"\"\"\n",
        "        Update Bayesian beliefs given the latest percept at the agent's\n",
        "        current location.\n",
        "\n",
        "        This should be called after each env.step(...) in the main loop.\n",
        "        \"\"\"\n",
        "        # Current agent location as tracked by MovePlanningAgent\n",
        "        # (Assumes MovePlanningAgent maintains self.x, self.y)\n",
        "        loc = (self.x, self.y)\n",
        "\n",
        "        # Record local percept evidence\n",
        "        self.breeze_history[loc] = bool(percept.breeze)\n",
        "        self.stench_history[loc] = bool(percept.stench)\n",
        "        if percept.scream:\n",
        "            self.heard_scream = True\n",
        "            self.wumpus_dead = True\n",
        "\n",
        "        # Recompute posteriors from all accumulated evidence\n",
        "        self.pit_probs = infer_pit_posteriors(\n",
        "            self.pit_model,\n",
        "            self.width,\n",
        "            self.height,\n",
        "            self.breeze_history,\n",
        "        )\n",
        "\n",
        "        self.wumpus_probs = infer_wumpus_posteriors(\n",
        "            self.wumpus_model,\n",
        "            self.width,\n",
        "            self.height,\n",
        "            self.stench_history,\n",
        "            self.wumpus_dead,\n",
        "        )\n",
        "\n",
        "        # Combine hazards into cell safety scores\n",
        "        self.safety = compute_safety_from_hazards(self.pit_probs, self.wumpus_probs)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Frontier selection and basic risk-based target choice\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    def _frontier_cells(self) -> list[Tuple[int, int]]:\n",
        "        \"\"\"\n",
        "        Frontier = all cells in the grid that:\n",
        "          - are within bounds, and\n",
        "          - have NOT yet been visited (i.e., not in self.visited_safe).\n",
        "\n",
        "        These are candidates for future exploration.\n",
        "        \"\"\"\n",
        "        frontier: list[Tuple[int, int]] = []\n",
        "        for x, y in all_cells(self.width, self.height):\n",
        "            if (x, y) not in self.visited_safe:\n",
        "                frontier.append((x, y))\n",
        "        return frontier\n",
        "\n",
        "    @staticmethod\n",
        "    def _manhattan_distance(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
        "        \"\"\"L1 distance between two grid cells.\"\"\"\n",
        "        (x1, y1), (x2, y2) = a, b\n",
        "        return abs(x1 - x2) + abs(y1 - y2)\n",
        "\n",
        "    def _select_best_frontier_cell(\n",
        "        self,\n",
        "        abort_risk_threshold: float = 0.5,\n",
        "    ) -> Tuple[Tuple[int, int] | None, float | None]:\n",
        "        \"\"\"\n",
        "        Select the \"best\" frontier cell to explore next based on current\n",
        "        safety beliefs.\n",
        "\n",
        "        For each frontier cell c:\n",
        "          - risk(c) = 1 - safety[c]\n",
        "        We choose:\n",
        "          - the cell with MINIMUM risk; ties broken by Manhattan distance\n",
        "            from the agent's current location (self.x, self.y).\n",
        "\n",
        "        If ALL frontier cells have risk > abort_risk_threshold, we return\n",
        "        (None, None) to signal that the agent should give up and go home.\n",
        "        \"\"\"\n",
        "        frontier = self._frontier_cells()\n",
        "        if not frontier:\n",
        "            return None, None  # nothing left to explore\n",
        "\n",
        "        # Compute risk for each frontier cell; default safety=0.0 if unknown.\n",
        "        risks: list[Tuple[Tuple[int, int], float]] = []\n",
        "        for cell in frontier:\n",
        "            s = self.safety.get(cell, 0.0)\n",
        "            risk = 1.0 - s\n",
        "            risks.append((cell, risk))\n",
        "\n",
        "        # Find minimum risk\n",
        "        min_risk = min(r for (_, r) in risks)\n",
        "\n",
        "        # If even the safest option is too risky, we should bail.\n",
        "        if min_risk > abort_risk_threshold:\n",
        "            return None, min_risk\n",
        "\n",
        "        # Among cells with risk == min_risk (within small epsilon),\n",
        "        # pick the one with the shortest Manhattan distance from current location.\n",
        "        eps = 1e-6\n",
        "        current = (self.x, self.y)\n",
        "        best_cell: Tuple[int, int] | None = None\n",
        "        best_dist: int | None = None\n",
        "\n",
        "        for cell, risk in risks:\n",
        "            if abs(risk - min_risk) > eps:\n",
        "                continue\n",
        "            dist = self._manhattan_distance(current, cell)\n",
        "            if best_cell is None or dist < best_dist:\n",
        "                best_cell = cell\n",
        "                best_dist = dist\n",
        "\n",
        "        return best_cell, min_risk\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Main control loop\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    def run(self, Environment, Action):\n",
        "        \"\"\"\n",
        "        Same overall structure as MovePlanningAgent.run, but:\n",
        "          - Maintains and updates Bayesian beliefs after every action.\n",
        "          - Uses risk-based planning instead of random exploration.\n",
        "          - May decide to bail out and climb even without gold if all\n",
        "            frontier cells are too risky.\n",
        "\n",
        "        If self.quiet is True, board visualization and print statements\n",
        "        are suppressed (useful for running many episodes).\n",
        "\n",
        "        At the end of the episode, self.outcome is one of:\n",
        "          - \"success\" : grabbed gold and climbed out at (1,1)\n",
        "          - \"death\"   : died in a pit or by the Wumpus\n",
        "          - \"bail\"    : climbed out at (1,1) without gold\n",
        "        \"\"\"\n",
        "        # 1) Initialize episode and environment\n",
        "        self.env = Environment()\n",
        "\n",
        "        percept = self.env.init(\n",
        "            width=self.width,\n",
        "            height=self.height,\n",
        "            pit_prob=self.pit_prob,\n",
        "            allow_climb_without_gold=self.allow_climb_without_gold,\n",
        "        )\n",
        "\n",
        "        # Reset agent state (same as MovePlanningAgent)\n",
        "        self.x, self.y, self.d = 1, 1, 0\n",
        "        self.has_gold = False\n",
        "        self.has_arrow = True\n",
        "        self.visited_safe = {(1, 1)}\n",
        "        self.plan.clear()\n",
        "        self.cumulative_reward = 0\n",
        "        self.outcome = \"unknown\"\n",
        "\n",
        "        # Reset per-episode arrow tracking\n",
        "        self.arrow_used_this_episode = False\n",
        "\n",
        "        # Reset belief-related state\n",
        "        self.breeze_history.clear()\n",
        "        self.stench_history.clear()\n",
        "        self.heard_scream = False\n",
        "        self.wumpus_dead = False\n",
        "        self._initialize_prior_beliefs()\n",
        "\n",
        "        # Initial beliefs from first percept\n",
        "        self.update_beliefs(percept)\n",
        "\n",
        "        # 2) Main perception–action loop\n",
        "        while not percept.done:\n",
        "            # Show board and current percept (unless quiet)\n",
        "            if not getattr(self, \"quiet\", False):\n",
        "                self.env.visualize()\n",
        "                print(\"Percept:\", percept)\n",
        "\n",
        "            # --- Step 1: deterministic reaction to glitter ---\n",
        "            if percept.glitter and not self.has_gold:\n",
        "                if not getattr(self, \"quiet\", False):\n",
        "                    print(\"\\nAction:\", Action.GRAB, \"\\n\")\n",
        "\n",
        "                percept = self.env.step(Action.GRAB)\n",
        "                self.cumulative_reward += percept.reward\n",
        "                self.has_gold = True\n",
        "\n",
        "                if not percept.done:\n",
        "                    self.visited_safe.add((self.x, self.y))\n",
        "\n",
        "                # Update beliefs at current location\n",
        "                self.update_beliefs(percept)\n",
        "\n",
        "                # Plan shortest safe path to start using visited_safe\n",
        "                self.plan = deque(\n",
        "                    bfs_shortest_actions(\n",
        "                        (self.x, self.y, self.d),\n",
        "                        (1, 1),\n",
        "                        self.visited_safe,\n",
        "                        self.width,\n",
        "                        self.height,\n",
        "                    )\n",
        "                    or []\n",
        "                )\n",
        "                continue\n",
        "\n",
        "            # --- Step 2: follow an existing plan, if any ---\n",
        "            if self.plan:\n",
        "                action = self._action_from_label(self.plan.popleft(), Action)\n",
        "                if not getattr(self, \"quiet\", False):\n",
        "                    print(\"\\nAction:\", action, \"\\n\")\n",
        "\n",
        "                # _act_and_update is inherited; it updates position,\n",
        "                # cumulative_reward, and visited_safe as in MovePlanningAgent\n",
        "                percept = self._act_and_update(action)\n",
        "                self.update_beliefs(percept)\n",
        "\n",
        "                # If plan finished at start, climb out (with or without gold).\n",
        "                if (\n",
        "                    not self.plan\n",
        "                    and (self.x, self.y) == (1, 1)\n",
        "                    and not percept.done\n",
        "                ):\n",
        "                    if not getattr(self, \"quiet\", False):\n",
        "                        print(\"\\nAction:\", Action.CLIMB, \"\\n\")\n",
        "\n",
        "                    percept = self._act_and_update(Action.CLIMB)\n",
        "                    self.update_beliefs(percept)\n",
        "                continue\n",
        "\n",
        "            # --- Step 3A: Shooting heuristic (before deciding next move) ---\n",
        "            # If the Wumpus is not dead and we still have the arrow,\n",
        "            # check whether the cell directly ahead has high probability of containing the Wumpus.\n",
        "\n",
        "            if not self.wumpus_dead and self.has_arrow:\n",
        "\n",
        "                # Compute the coordinates of the cell in front\n",
        "                dx, dy = ORIENTATION_DELTAS[self.d]\n",
        "                fx, fy = self.x + dx, self.y + dy\n",
        "\n",
        "                # Check if forward cell is inside the grid\n",
        "                if 1 <= fx <= self.width and 1 <= fy <= self.height:\n",
        "\n",
        "                    # Probability Wumpus is there\n",
        "                    p_wumpus_forward = self.wumpus_probs.get((fx, fy), 0.0)\n",
        "\n",
        "                    # Threshold: shoot only if forward cell has high Wumpus probability\n",
        "                    if p_wumpus_forward >= 0.45:  # you can tune this\n",
        "                        if not getattr(self, \"quiet\", False):\n",
        "                            print(\n",
        "                                \"\\nAction:\",\n",
        "                                Action.SHOOT,\n",
        "                                f\"(p_wumpus={p_wumpus_forward:.2f})\\n\",\n",
        "                            )\n",
        "\n",
        "                        percept = self._act_and_update(Action.SHOOT)\n",
        "                        self.has_arrow = False\n",
        "                        self.arrow_used_this_episode = True\n",
        "                        self.update_beliefs(percept)\n",
        "\n",
        "                        # After shooting, skip movement decision and continue main loop\n",
        "                        continue\n",
        "\n",
        "            # --- Step 3: no plan, no glitter -> decide what to do next ---\n",
        "\n",
        "            # Choose safest frontier cell, or decide to bail out\n",
        "            target_cell, min_risk = self._select_best_frontier_cell(\n",
        "                abort_risk_threshold=0.5  # can tune as hyperparameter\n",
        "            )\n",
        "\n",
        "            if target_cell is None:\n",
        "                # Either no frontier or all options too risky => bail out\n",
        "                if (self.x, self.y) == (1, 1):\n",
        "                    # Already at start: climb and end episode\n",
        "                    if not getattr(self, \"quiet\", False):\n",
        "                        print(\"\\nAction:\", Action.CLIMB, \"\\n\")\n",
        "\n",
        "                    percept = self._act_and_update(Action.CLIMB)\n",
        "                    self.update_beliefs(percept)\n",
        "                    continue\n",
        "\n",
        "                # Otherwise, plan a safe path back to (1,1) using visited_safe\n",
        "                self.plan = deque(\n",
        "                    bfs_shortest_actions(\n",
        "                        (self.x, self.y, self.d),\n",
        "                        (1, 1),\n",
        "                        self.visited_safe,\n",
        "                        self.width,\n",
        "                        self.height,\n",
        "                    )\n",
        "                    or []\n",
        "                )\n",
        "                # Next loop iteration will execute the plan\n",
        "                continue\n",
        "\n",
        "            # We have a target frontier cell (x, y)\n",
        "            tx, ty = target_cell\n",
        "            safe_for_planning = set(self.visited_safe)\n",
        "            safe_for_planning.add((tx, ty))\n",
        "\n",
        "            plan_labels = bfs_shortest_actions(\n",
        "                (self.x, self.y, self.d),\n",
        "                (tx, ty),\n",
        "                safe_for_planning,\n",
        "                self.width,\n",
        "                self.height,\n",
        "            )\n",
        "\n",
        "            if not plan_labels:\n",
        "                # BFS failed (e.g., target not reachable via our current safe set).\n",
        "                # As a conservative fallback, take a random local action like the\n",
        "                # MovePlanningAgent.\n",
        "                action = self.rng.choice(\n",
        "                    [Action.FORWARD, Action.LEFT, Action.RIGHT, Action.SHOOT]\n",
        "                )\n",
        "                if not getattr(self, \"quiet\", False):\n",
        "                    print(\"\\nAction:\", action, \"\\n\")\n",
        "\n",
        "                # If we randomly choose to shoot and still have the arrow,\n",
        "                # mark it as used and clear has_arrow.\n",
        "                if action == Action.SHOOT and self.has_arrow:\n",
        "                    self.has_arrow = False\n",
        "                    self.arrow_used_this_episode = True\n",
        "\n",
        "                percept = self._act_and_update(action)\n",
        "                self.update_beliefs(percept)\n",
        "                continue\n",
        "\n",
        "            # Store the planned route; next loop iteration will follow it.\n",
        "            self.plan = deque(plan_labels)\n",
        "            # loop continues; plan branch will run next\n",
        "\n",
        "        # 3) Classify episode outcome for statistics\n",
        "        if (self.x, self.y) == (1, 1):\n",
        "            if self.has_gold:\n",
        "                self.outcome = \"success\"   # grabbed gold and escaped\n",
        "            else:\n",
        "                self.outcome = \"bail\"      # climbed out without gold\n",
        "        else:\n",
        "            self.outcome = \"death\"         # died in pit or by Wumpus\n",
        "\n",
        "        # Final board & summary\n",
        "        if not getattr(self, \"quiet\", False):\n",
        "            try:\n",
        "                self.env.visualize()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            print(\"Percept:\", percept)\n",
        "            print(\"Cumulative reward:\", self.cumulative_reward)\n",
        "\n",
        "        return self.cumulative_reward\n"
      ],
      "metadata": {
        "id": "FeSGsTYvTPgf"
      },
      "id": "FeSGsTYvTPgf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Of The Game State"
      ],
      "metadata": {
        "id": "52DhALBq4ydL"
      },
      "id": "52DhALBq4ydL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity tests"
      ],
      "metadata": {
        "id": "KqwYax3qVA-9"
      },
      "id": "KqwYax3qVA-9"
    },
    {
      "cell_type": "code",
      "source": [
        "env = Environment()\n",
        "# p0 = env.init(width=4, height=4, pit_prob=0.0, allow_climb_without_gold=True) # Safe world (no pits)\n",
        "p1 = env.init(width=4, height=4, pit_prob=0.2, allow_climb_without_gold=True)\n",
        "env.visualize()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki-rNIjwDx1G",
        "outputId": "0ff5e556-9b2e-45d0-ea1a-e749c25f21d0"
      },
      "id": "ki-rNIjwDx1G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    |    |    |P   |\n",
            "|W   |    |    |    |\n",
            "|    |G   |    |    |\n",
            "|A→  |    |    |P   |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Path with pits disabled (should sometimes succeed quickly):\n",
        "\n",
        "# move_planning_agent_happy = MovePlanningAgent(pit_prob=0.0)\n",
        "# move_planning_agent_happy.run(Environment, Action)"
      ],
      "metadata": {
        "id": "GnNV6k4-VGfD"
      },
      "id": "GnNV6k4-VGfD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Planner sanity (inline harness):\n",
        "safe_line = {(1,1),(2,1),(3,1),(4,1)}\n",
        "plan = bfs_shortest_actions(start=(1,1,0), goal_cell=(4,1),\n",
        "                            safe_cells=safe_line, width=4, height=4)\n",
        "print(plan)  # expect ['Forward','Forward','Forward']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqqTEyhVWAyp",
        "outputId": "bbd6d66f-6f25-4844-ab7a-a9da60ba335b"
      },
      "id": "FqqTEyhVWAyp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Forward', 'Forward', 'Forward']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn cost check\n",
        "plan = bfs_shortest_actions(start=(1,1,1), goal_cell=(2,1),\n",
        "                            safe_cells={(1,1),(2,1)}, width=4, height=4)\n",
        "print(plan)  # one of ['TurnRight','TurnRight','Forward'] or ['TurnLeft','Forward']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBAtA3XWOGl",
        "outputId": "9666ec94-f40f-4db8-8d68-c9d44b863c9c"
      },
      "id": "dqBAtA3XWOGl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TurnLeft', 'Forward']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Playing Game"
      ],
      "metadata": {
        "id": "ZrdkVbyUAIaf"
      },
      "id": "ZrdkVbyUAIaf"
    },
    {
      "cell_type": "code",
      "source": [
        "# NAIVE AGENT\n",
        "\n",
        "# naive_agent = NaiveAgent(width=4, height=4, pit_prob=0.2, allow_climb_without_gold=False)\n",
        "# naive_agent.run()\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# MOVE PLANNING AGENT\n",
        "\n",
        "# move_planning_agent = MovePlanningAgent(width=4, height=4, pit_prob=0.2, allow_climb_without_gold=False)\n",
        "# move_planning_agent.run(Environment, Action)\n",
        "\n",
        "# --------------------------------------------------------------------------------------------------\n",
        "\n",
        "#PROBABILISTIC AGENT\n",
        "\n",
        "agent = ProbAgent(width=4, height=4, pit_prob=0.2, allow_climb_without_gold=True)\n",
        "agent.run(Environment, Action)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzKX_iqM7dYB",
        "outputId": "123a1423-2908-47c6-b891-f3fe2d7e0bd7"
      },
      "id": "tzKX_iqM7dYB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-14819521.py:31: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  X_masked = masked.MaskedTensor(X, mask=mask)\n",
            "/tmp/ipython-input-14819521.py:88: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  X_masked = masked.MaskedTensor(X, mask=mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|P   |    |    |    |\n",
            "|A→  |    |P   |    |\n",
            "Percept: Percept(t=0, Signals=[Breeze], Reward=0, Done=False)\n",
            "\n",
            "Action: Action.SHOOT \n",
            "\n",
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|P   |    |    |    |\n",
            "|A→  |    |P   |    |\n",
            "Percept: Percept(t=1, Signals=[Breeze], Reward=-11, Done=False)\n",
            "\n",
            "Action: Action.RIGHT \n",
            "\n",
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|P   |    |    |    |\n",
            "|A↓  |    |P   |    |\n",
            "Percept: Percept(t=2, Signals=[Breeze], Reward=-1, Done=False)\n",
            "\n",
            "Action: Action.RIGHT \n",
            "\n",
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|P   |    |    |    |\n",
            "|A←  |    |P   |    |\n",
            "Percept: Percept(t=3, Signals=[Breeze], Reward=-1, Done=False)\n",
            "\n",
            "Action: Action.SHOOT \n",
            "\n",
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|P   |    |    |    |\n",
            "|A←  |    |P   |    |\n",
            "Percept: Percept(t=4, Signals=[Breeze], Reward=-1, Done=False)\n",
            "\n",
            "Action: Action.SHOOT \n",
            "\n",
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|P   |    |    |    |\n",
            "|A←  |    |P   |    |\n",
            "Percept: Percept(t=5, Signals=[Breeze], Reward=-1, Done=False)\n",
            "\n",
            "Action: Action.RIGHT \n",
            "\n",
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|P   |    |    |    |\n",
            "|A↑  |    |P   |    |\n",
            "Percept: Percept(t=6, Signals=[Breeze], Reward=-1, Done=False)\n",
            "\n",
            "Action: Action.FORWARD \n",
            "\n",
            "|    |    |WG  |    |\n",
            "|    |    |    |    |\n",
            "|A↑P |    |    |    |\n",
            "|    |    |P   |    |\n",
            "Percept: Percept(t=7, Signals=[Breeze], Reward=-1001, Done=True)\n",
            "Cumulative reward: -1017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1017"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running game for 1000 episodes"
      ],
      "metadata": {
        "id": "K39AMgNan-jV"
      },
      "id": "K39AMgNan-jV"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_agent(num_episodes=1000, verbose_every=100):\n",
        "    \"\"\"\n",
        "    Run ProbAgent for num_episodes games and report:\n",
        "      - average reward\n",
        "      - counts and rates of success / death / bailout\n",
        "      - how many episodes the arrow was used at least once\n",
        "    \"\"\"\n",
        "    print(f\"Starting evaluation for {num_episodes} episodes...\")\n",
        "\n",
        "    total_reward = 0.0\n",
        "    rewards = []\n",
        "\n",
        "    success_count = 0\n",
        "    death_count = 0\n",
        "    bailout_count = 0\n",
        "\n",
        "    # counts how many *episodes* used the arrow at least once\n",
        "    shots_fired = 0\n",
        "\n",
        "    for ep in range(1, num_episodes + 1):\n",
        "        agent = ProbAgent(\n",
        "            width=4,\n",
        "            height=4,\n",
        "            pit_prob=0.2,\n",
        "            allow_climb_without_gold=True,\n",
        "        )\n",
        "        agent.quiet = True\n",
        "\n",
        "        reward = agent.run(Environment, Action)\n",
        "        rewards.append(reward)\n",
        "        total_reward += reward\n",
        "\n",
        "        # explicit per-episode arrow flag\n",
        "        if getattr(agent, \"arrow_used_this_episode\", False):\n",
        "            shots_fired += 1\n",
        "\n",
        "        # classify outcome from reward\n",
        "        if reward >= 500:\n",
        "            success_count += 1\n",
        "        elif reward <= -1000:\n",
        "            death_count += 1\n",
        "        else:\n",
        "            bailout_count += 1\n",
        "\n",
        "        if verbose_every and ep % verbose_every == 0:\n",
        "            print(f\"Episode {ep}: running average reward = {total_reward / ep:.2f}\")\n",
        "\n",
        "    avg_reward = total_reward / num_episodes\n",
        "\n",
        "    print(\"\\n=== Evaluation summary ===\")\n",
        "    print(f\"Episodes:               {num_episodes}\")\n",
        "    print(f\"Average reward:         {avg_reward:.2f}\")\n",
        "    print(f\"Min reward:             {min(rewards):.2f}\")\n",
        "    print(f\"Max reward:             {max(rewards):.2f}\")\n",
        "    print()\n",
        "    print(f\"Successes (gold+escape): {success_count} ({success_count/num_episodes:.1%})\")\n",
        "    print(f\"Deaths:                  {death_count} ({death_count/num_episodes:.1%})\")\n",
        "    print(f\"Bailouts w/o gold:       {bailout_count} ({bailout_count/num_episodes:.1%})\")\n",
        "    print(f\"Episodes where arrow was fired: {shots_fired} ({shots_fired/num_episodes:.1%})\")\n",
        "\n",
        "    return rewards, avg_reward, {\n",
        "        \"success\": success_count,\n",
        "        \"death\": death_count,\n",
        "        \"bail\": bailout_count,\n",
        "        \"shots_fired\": shots_fired,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "3M8ExVgkfTJV"
      },
      "id": "3M8ExVgkfTJV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run ProbAgent for 1000 episodes and report average score\n",
        "rewards, avg_reward, outcome_stats = evaluate_agent(num_episodes=1000, verbose_every=500)\n",
        "# print(\"Done. Final average reward:\", avg_reward)\n",
        "print(\"Outcome stats:\", outcome_stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agidb0jsRAbw",
        "outputId": "8922489d-f37d-42cc-86a4-9bb42b162299"
      },
      "id": "agidb0jsRAbw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting evaluation for 1000 episodes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-14819521.py:31: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  X_masked = masked.MaskedTensor(X, mask=mask)\n",
            "/tmp/ipython-input-14819521.py:88: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  X_masked = masked.MaskedTensor(X, mask=mask)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 500: running average reward = -160.63\n",
            "Episode 1000: running average reward = -128.41\n",
            "\n",
            "=== Evaluation summary ===\n",
            "Episodes:               1000\n",
            "Average reward:         -128.41\n",
            "Min reward:             -1184.00\n",
            "Max reward:             993.00\n",
            "\n",
            "Successes (gold+escape): 434 (43.4%)\n",
            "Deaths:                  534 (53.4%)\n",
            "Bailouts w/o gold:       32 (3.2%)\n",
            "Episodes where arrow was fired: 666 (66.6%)\n",
            "Outcome stats: {'success': 434, 'death': 534, 'bail': 32, 'shots_fired': 666}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}